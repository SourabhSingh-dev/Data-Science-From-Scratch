## 🗓️ Day 29 – 11/10/2025 

### 📍 Status: ✅ Completed 

---

## ✅ What I did today: 

### 📌 Topics Reviewed & Practiced: 
- 🧪 **Hypothesis Testing (Detailed Practice)**
  - **Null and Alternative Hypotheses:** Practiced formulating H0 and H1 for various scenarios.
  - **Critical Regions and Rejection Rules:** Reviewed how the significance level ($\alpha$) defines the critical region for both one-tailed and two-tailed tests.
  - **Type I and Type II Errors:** Understood the trade-off between False Positives ($\alpha$) and False Negatives ($\beta$) and the importance of selecting an appropriate $\alpha$ level.
  - **Z-Test**

---

## 🧩 Practice & Execution: 
- Solved several numerical problems involving calculating t-scores and comparing them to critical values.
- Analyzed real-world examples where rejecting a null hypothesis (e.g., $\text{H}_0: \beta_{\text{feature}} = 0$) has practical implications for model and business decisions.
- Reviewed how to interpret statistical results from software output (e.g., Python's `statsmodels` summary tables).

---

## 📘 Resources Used: 
- 📄 Statistics textbooks and detailed Hypothesis Testing worksheets.
- 💻 Python console for quick calculations related to t-scores and P-values.
- 🔗 Deep dive videos on the intuition behind the F-distribution.

---

## 🔄 Next Up: 
- Implement **Polynomial Regression in Python** (as planned from Day 27).
- Directly apply F-test and t-test concepts to evaluate the performance of both Linear and Polynomial regression models using the statistical summary.
- Focus on visualizing the trade-off between model fit ($\text{R}^2$) and statistical significance.

---

## 📝 Reflections: 
- Detailed study of hypothesis testing provides a concrete way to justify feature inclusion and model complexity, moving beyond simple $\text{R}^2$ values.
- The power of the T-test to isolate the impact of a single variable is a crucial skill for model explainability.
- Ready to see these statistical tests in action within a practical coding session tomorrow.