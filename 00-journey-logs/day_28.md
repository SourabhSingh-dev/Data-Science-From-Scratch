# ğŸ—“ï¸ Day 28 â€“ 10/10/2025 
(Post mid sem exams)
### ğŸ“ Status: âœ… Completed 

---

## âœ… What I did today: 

### ğŸ“Œ Topics Reviewed & Practiced: 
- ğŸ“Š **Regression Analysis & Statistical Foundations**
  - **Regression Analysis:** Deep dive into the interpretation of regression model outputs.
  - **P-Statistics & P-Value:** Reviewed the concept of the P-value in hypothesis testing, and its role in determining the statistical significance of predictors in a regression model.
  - **T-Statistics:** Understood the T-statistic and its relation to the P-value, used for testing individual coefficient significance (i.e., whether a specific feature is a useful predictor).
  - **Statistical Inference in Machine Learning:** Explored the fundamental idea that every ML problem is, at its core, a problem of statistical inference.
    - Insight: Models learn from a sample of data to make predictions about a larger, unseen population, which is the definition of statistical inference.
- **Other Key Statistical Concepts:** Covered concepts surrounding model evaluation and the underlying probabilistic nature of ML.

---

## ğŸ§© Practice & Execution: 
- Worked through examples to calculate and interpret P and T statistics for sample regression outputs.
- Reviewed why the assumption of linearity/normality is often a simplification in real-world ML problems.
- Solidified the understanding of **hypothesis testing** in the context of feature selection.

---

## ğŸ“˜ Resources Used: 
- ğŸ“„ Dedicated notes on Statistical Inference and Regression.
- ğŸ”— Online articles and academic papers explaining the link between ML and statistical inference.
- ğŸ’» Whiteboard practice for deriving P and T values.

---

## ğŸ”„ Next Up: 
- Return to **Polynomial Regression Implementation** (from Day 27 plan).
- Apply the concepts of P-values and T-statistics to evaluate the significance of the new polynomial features in the code implementation.

---

## ğŸ“ Reflections: 
- Today provided a crucial theoretical foundation, linking the practical side of ML (model building) with the mathematical rigor of statistics.
- Understanding why "every ML problem is statistical inference" clarifies the purpose and limitations of models.
- The T/P statistics are the "sanity checks" for feature effectiveness.