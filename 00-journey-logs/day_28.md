# 🗓️ Day 28 – 10/10/2025 
(Post mid sem exams)
### 📍 Status: ✅ Completed 

---

## ✅ What I did today: 

### 📌 Topics Reviewed & Practiced: 
- 📊 **Regression Analysis & Statistical Foundations**
  - **Regression Analysis:** Deep dive into the interpretation of regression model outputs.
  - **P-Statistics & P-Value:** Reviewed the concept of the P-value in hypothesis testing, and its role in determining the statistical significance of predictors in a regression model.
  - **T-Statistics:** Understood the T-statistic and its relation to the P-value, used for testing individual coefficient significance (i.e., whether a specific feature is a useful predictor).
  - **Statistical Inference in Machine Learning:** Explored the fundamental idea that every ML problem is, at its core, a problem of statistical inference.
    - Insight: Models learn from a sample of data to make predictions about a larger, unseen population, which is the definition of statistical inference.
- **Other Key Statistical Concepts:** Covered concepts surrounding model evaluation and the underlying probabilistic nature of ML.

---

## 🧩 Practice & Execution: 
- Worked through examples to calculate and interpret P and T statistics for sample regression outputs.
- Reviewed why the assumption of linearity/normality is often a simplification in real-world ML problems.
- Solidified the understanding of **hypothesis testing** in the context of feature selection.

---

## 📘 Resources Used: 
- 📄 Dedicated notes on Statistical Inference and Regression.
- 🔗 Online articles and academic papers explaining the link between ML and statistical inference.
- 💻 Whiteboard practice for deriving P and T values.

---

## 🔄 Next Up: 
- Return to **Polynomial Regression Implementation** (from Day 27 plan).
- Apply the concepts of P-values and T-statistics to evaluate the significance of the new polynomial features in the code implementation.

---

## 📝 Reflections: 
- Today provided a crucial theoretical foundation, linking the practical side of ML (model building) with the mathematical rigor of statistics.
- Understanding why "every ML problem is statistical inference" clarifies the purpose and limitations of models.
- The T/P statistics are the "sanity checks" for feature effectiveness.